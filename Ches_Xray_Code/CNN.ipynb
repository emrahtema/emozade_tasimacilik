{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/emrah.tema/.virtualenvs/jupyter/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D # full connection yapar\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense # full connection yapmaz\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-255 olan pixel değerlerini 0-1 arasına sığacak şekilde scale eder\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "                                        rescale=1./255,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('chest_xray/train',\n",
    "                                                target_size=(64, 64), # resim input shape ile aynı\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary') # iki sınıfımız var diye binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('chest_xray/test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(64, (3, 3), input_shape = (64, 64, 3), activation = \"relu\"))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.15))\n",
    "classifier.add(Convolution2D(64,(5,5),activation='relu'))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.15))\n",
    "classifier.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.15))\n",
    "classifier.add(Convolution2D(128,(3,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D((2,2)))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dropout(0.15))\n",
    "classifier.add(GlobalAveragePooling2D())\n",
    "classifier.add(Dense(units = 1000, activation='relu'))\n",
    "classifier.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "#classifier.add(Convolution2D(64, (3, 3), input_shape = (128, 128, 3), activation = \"relu\"))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#classifier.add(Flatten())\n",
    "#classifier.add(Dense(units = 32, activation = \"relu\"))\n",
    "\n",
    "#classifier.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5216/5216 [==============================] - 2713s 520ms/step - loss: 0.1290 - accuracy: 0.9505 - val_loss: 0.3193 - val_accuracy: 0.9006\n",
      "Epoch 2/3\n",
      "5216/5216 [==============================] - 2737s 525ms/step - loss: 0.0782 - accuracy: 0.9707 - val_loss: 0.3144 - val_accuracy: 0.8799\n",
      "Epoch 3/3\n",
      "2429/5216 [============>.................] - ETA: 22:56 - loss: 0.0639 - accuracy: 0.9759"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "                        training_set,\n",
    "                        steps_per_epoch=5216,\n",
    "                        epochs=3,\n",
    "                        validation_data=test_set,\n",
    "                        validation_steps=624)\n",
    "# val'lı ifadeler test verisinin sonuçları\n",
    "classifier.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img(\"chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg\", target_size = (128, 128))\n",
    "test_image = image.img_to_array(test_image)\n",
    "# resme dördüncü bir boyut eklemek gerekiyor hata almamak için\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = new_model.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 / 390\n",
      "0.7897435897435897\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "c = 0\n",
    "for file in os.listdir(\"chest_xray/test/PNEUMONIA\"):\n",
    "    if file.endswith(\".jpeg\"):\n",
    "        test_image = image.load_img(\"chest_xray/test/PNEUMONIA/\" + file, target_size = (128, 128))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = classifier.predict(test_image)\n",
    "        if result[0][0] == 1:\n",
    "            counter += 1\n",
    "        c += 1\n",
    "print(counter, \"/\", c)\n",
    "print((1/c)*counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
