{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir RBM oluşturup kullanıcıların bir filmi beğenip beğenmeyeceğini tahmin ettireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie's id, name, contents 3883 \n",
      "    0                        1                             2\n",
      "0  1         Toy Story (1995)   Animation|Children's|Comedy\n",
      "1  2           Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2  3  Grumpier Old Men (1995)                Comedy|Romance \n",
      "\n",
      "user's id, sex, age, job, zip code 6040 \n",
      "    0  1   2   3      4\n",
      "0  1  F   1  10  48067\n",
      "1  2  M  56  16  70072\n",
      "2  3  M  25  15  55117 \n",
      "\n",
      "user's id, movie's id, ratings(1-5), timesteps 1000209 \n",
      "    0     1  2          3\n",
      "0  1  1193  5  978300760\n",
      "1  1   661  3  978302109\n",
      "2  1   914  3  978301968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing the dataset\n",
    "# default seperatör ',' oluyor ama film isimleri virgünl içerebildiği için farklı seperator kullanıyoruz\n",
    "# sütun başlıkları olmadığı için None, bazı film isimleri utf-8'de olmayan özel karakterler içeriyor\n",
    "movies = pd.read_csv(\"data/BM/ml-1m/movies.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "users = pd.read_csv(\"data/BM/ml-1m/users.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "ratings = pd.read_csv(\"data/BM/ml-1m/ratings.dat\", sep = \"::\", header = None, engine = \"python\", encoding = \"latin-1\")\n",
    "print(\"movie\\'s id, name, contents\", len(movies), \"\\n\", movies[:3], \"\\n\")\n",
    "print(\"user's id, sex, age, job, zip code\", len(users), \"\\n\", users[:3], \"\\n\")\n",
    "print(\"user's id, movie's id, ratings(1-5), timesteps\", len(ratings), \"\\n\", ratings[:3], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79999 19999\n",
      "[[        1         2         3 876893171]\n",
      " [        1         3         4 878542960]\n",
      " [        1         4         3 876893119]]\n",
      "[[        1        10         3 875693118]\n",
      " [        1        12         5 878542960]\n",
      " [        1        14         5 874965706]]\n"
     ]
    }
   ],
   "source": [
    "# preparing train and testset\n",
    "# bu klasörde 100k veri k=5 fold cros validation için 5e bölünmüş durumda base=train test=test, ama sadece birini kullanacağız\n",
    "training_set = pd.read_csv(\"data/BM/ml-100k/u1.base\", delimiter = \"\\t\")\n",
    "training_set = np.array(training_set, dtype = \"int\")\n",
    "test_set = pd.read_csv(\"data/BM/ml-100k/u1.test\", delimiter = \"\\t\")\n",
    "test_set = np.array(test_set, dtype = \"int\")\n",
    "print(len(training_set), len(test_set))\n",
    "print(training_set[:3])\n",
    "print(test_set[:3]) # yukarıdaki ratings'in aynısı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "# Kişiler için matrisler oluşturacağız hangi tarz filmleri beğendiklerine yönelik, max id alsak users sayısını buluruz\n",
    "nb_users = max(max(training_set[:, 0]), max(test_set[:, 0]))\n",
    "nb_movies = max(max(training_set[:, 1]), max(test_set[:, 1]))\n",
    "print(nb_users, nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM matris verisi istediği için users are rows & movies are columns olan matrixler oluşturuyoruz\n",
    "def convert(data):\n",
    "    new_data = list()\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users] # data[rows][condition], kullanıcının oyladığı filmleri aldık\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users] # puanlamadığı filmler 0'lar ile doldurulacak\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings)) # torch expects list of lists\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 3.0, 4.0, 3.0, 3.0, 0.0, 4.0, 1.0, 5.0, 0.0, 2.0, 0.0, 5.0, 0.0, 5.0, 5.0, 0.0, 4.0, 5.0, 0.0, 1.0, 4.0, 0.0, 0.0, 4.0, 3.0, 0.0, 4.0, 1.0, 3.0, 0.0, 5.0, 0.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 3.0,\n"
     ]
    }
   ],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "print(str(training_set[0])[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 3., 4.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Converting the data into Torch tensors\n",
    "# Tensorler(multi dimensional matrix with single type) npArray'lerden daha etkili ve hızlı işlem yapılabilmesini sağlıyorlar\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "print(training_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.,  1.,  1.,  ..., -1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "# Converting the ratings into binary ratings 1(like) or 0(not)\n",
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0 # tensorde OR yok, normalde var\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0 # tensorde OR yok, normalde var\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1\n",
    "print(training_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Architecture of the RBM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    \n",
    "    # nv number of visible nodes, nh number of hidden nodes\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv) # initilize random weights\n",
    "        self.a = torch.randn(1, nh) # bias for hidden nodes (2 boyutlu dizi ister), 1 = batch size\n",
    "        self.b = torch.randn(1, nv) # bias for visible nodes\n",
    "    \n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t()) # mm = tensorXtensor, t() = transpoz\n",
    "        activation = wx + self.a.expand_as(wx) # bias is applied to every minibatch(1 yukarıda)\n",
    "        # Probability of Hidden node is activated for Given Visible node\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v) # bernoulli(..) gives sampling of the hidden neurons\n",
    "    \n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(),ph0) - torch.mm(vk.t(),phk)).t() # first update\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100 # num of features\n",
    "batch_size = 100 # for fast training choose a high size\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: tensor(0.3309)\n",
      "Epoch: 2 Loss: tensor(0.2477)\n",
      "Epoch: 3 Loss: tensor(0.2499)\n",
      "Epoch: 4 Loss: tensor(0.2504)\n",
      "Epoch: 5 Loss: tensor(0.2469)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 5\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    counter = 0. # float\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user : id_user + batch_size] # input batch of observations\n",
    "        v0 = training_set[id_user : id_user + batch_size] # output batch of observations\n",
    "        ph0,_ = rbm.sample_h(v0) # x,_ don't take the seccond returned value\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0 < 0] = v0[v0 < 0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        # v0 değişmeyen visible nodelar, vk güncellenen nodelar son halleri\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        counter += 1.\n",
    "    print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(train_loss / counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the RBM\n",
    "Markov Chain Monte Carlo (blind walk) technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: tensor(0.2581)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "counter = 0.\n",
    "for id_user in range(nb_users): # test with each user\n",
    "    v = training_set[id_user : id_user + 1]\n",
    "    vt = test_set[id_user : id_user + 1] # target\n",
    "    if len(vt[vt >= 0]) > 0: # -1 olan oylamaları kabul etmiyoruz zaten oylanmamış demekti\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt >= 0] - v[vt >= 0]))\n",
    "        counter += 1.0\n",
    "print(\"Test loss: \" + str(test_loss / counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sınıfa predict için eklenebilir<br><br>\n",
    "\n",
    "def predict( self, x): # x: visible nodes<br>\n",
    "  _, h = self.sample_h( x)<br>\n",
    "  _, v = self.sample_v( h)<br>\n",
    "  return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
