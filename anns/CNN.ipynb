{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN, Kendisinden önce convolution işlemleri içeren bir derin öğrenme sinir ağıdır. Resimler ve videolar için kullanılır.<br>\n",
    "Veri setimizde kedi ve köpek resimleri bulunmakta ve CNN'yi kedi ve köpekleri ayırt edebilecek şekilde eğiteceğiz.<br><br>\n",
    "Genelde resim veri setini koda dönüştürme işleminde her bir sınıfa ait resmin ismi o sınıf ismiyle başlar ve ardından sıra sayısı alır. Örneğin eğitim verimizdeki köpek resimleri dog.1, dog.2, ..., dog.5000 diye gidiyor. Bu resimlerin her birini yükleyip 3 boyutlu diziler oluşturup resim isimlerini label olarak ele aldığımızda her bir resmin sınıfı zaten kendi isminde yazıyor olacaktır ve buna göre işlemler yapılır. Ama burada keras'ın sunduğu bir avantajı kullanacağız, resimlerin ismine değil de o resimlerin bulunduğu klasör isimlerini sınıf olarak kullanacağız bunun için kedi ve köpek resimleri farklı klasörlerde bulunmaktadırlar, böylesi daha kolay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D # full connection yapar\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense # full connection yapmaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutionn -> max pooling -> flattening -> full connection\n",
    "\n",
    "# initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution2D(Number of Feature Maps(filters), (Number of Rows in Filters, Number of Cols in Filters), border_mode, input_shape(dimensions of each channel, //, number of channels))<br>\n",
    "Feature Maps sayısı genellikle 32 ile başlamalı ve ardışık katmanlarda artarak devam etmelidir 64, 128, 256 ...<br>\n",
    "border mod resimdeki kenarlıkları nasıl işleyeceğiyle alakalıdır, genellikle \"same\" uygulanır.<br>\n",
    "input shape, resim verimizin dönüştürüldüğü format bilgisini ister. Renkli resimler için ilk iki parametre boyutu olur, son parametre ise 3 olur 3 boyutlu olduğundan.<br>\n",
    "Bizim işlemlerimizde renk bilgisini koruyabilmek için 3 seçiyoruz, çünkü kedi ile köpekler arasında renk farklılıkları vardır. Format olarka da 64x64 seçmek işimize yarayacaktır çünkü daha büyük formatlar çok daha uzun zamanlar gerektirir ve o kadar beklemeyelim şimdi saatlerce. Resmin boyutu ufak olsada bu sınıflandırmada işe yarayacaktır. Yine bunlarıda 32, 64, 128, ... diye seçmeliyiz. Örn bu sınıflandırma için 256x256 seçersek 8 saate yakın sürecektir eğitim işlemi.<br>\n",
    "Feature map'lerde herhangi bir negatif değer olmadığından emin olmak için katmanlara aktivasyon fonksiyonu eklemeyi de ihmal etmiyoruz, çünkü illa oluyor negatif değerler. Aktivasyon fonksiyonu olarak Rectifier kullanıyoruz yani relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution (input image X feature detector -> feature map)\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening stepte daha az node - nöron olması için pooling yapıyoruz. Süredek oldukça kazandırırken performanstan bir şey kaybettirmiyor ve yoğun hesaplamaların önüne geçiyoruz. Bilgi kaybının önüne geçebileceğimiz en iyi max pool boyutu 2x2 olarak tecrübe edildiğinden 2x2 seçiyoruz. Kısaca feature map boyutlarımız düşürülüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling (each feature map X max pooling -> pooled feature map)\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max pool ile boyutlarını düşürüp kendilerini yarıya bölsek de hala elimizde çok fazla sayıda pooled feature maps olacaktır. Çok boyutlu bir vektörü tek boyuta indirgemek de boyutunu düşürür. E direkt resme flattening uygulasak şu önceki adımları(Conv step, maxpool step) atlasak ne olur? Bu durumda her bir pixel bilgisini kaydetmiş oluruz, ama bu pixellerin etraflarındaki pixellerle ilişkilerini ağa anlatamayız, yani bir bilgi çıkarımı yapılamaz.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening (nXn boyutlu pooled feature maps X flattening -> bir boyutlu array)\n",
    "# pfm[[1,2,3],[4,5,6],[7,8,9]] -> pfm[1,2,3,4,5,6,7,8,9]\n",
    "# pfm1, pfm2, pfm3,...,pfmn -> [pfm1, pfm2, pfm3, ..., pfmn]\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node sayısı olarak giriş ve çıkış nöronlarının sayısı diyorduk ama burada bir sürü pool olduğundan numaralarını hesap etmek zor olacaktır. O yüzden küçük olmayan sabit bir sayı seçiyoruz 128(büyüdükçe eğitim daha çok vakit alır), genelde 100 civarında bir node seçimi yapılır ama 2nin kuvveti olması daha iyi oluyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Connection (hidden layer) (flattened pooled feature maps -> are inputs)\n",
    "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "\n",
    "# output layer\n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\")) # binary çıkış var sigmoid yeterli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# iki sınıf var diye binary ce seçtik, eğer ikiden fazla olaydı categorical_crossentropy seçerdik\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Image Agumentation Process</b><br>\n",
    "Eğer bu adım yapılmazsa train accuracysi yüksek olur ama test düşük olur, kısaca overfitting gerçekleşir, bu gerçekleşmesin diye bu adımın yapılması gereklidir. Overfitting nasıl oluşur? Elimizde, ağın bütün özellikler arasındaki ilişkiyi doğru şekilde bulabileceği kadar eğitim resim verisi yoksa, yani aslında az resim varsa ağ bu resimleri ve özellikler-pixeller arasındaki ilişkileri öğrenir ama ve yüksek doğruluk oranı verir ama aslında daha fazla özellik ilişkisi öğrenmesi gerekiyordur, geliştirilmesi lazımdır, bu yüzden de test accuracysi düşük çıkar. Bizim eğitim için 8k, test için 2k resmimiz var ama bu aslında iyi bir ağ eğitmek için iyi bir sayı değildir. Bu durumda işte agumentation yapmak işimizi çözer. Bu agumentation işlemi resimlerimizden bir sürü kümelenmeler oluşturur, bu kümelere yerleştirilmiş rasgele resimlere yine rasgele işlemler uygular, resmi kaydırma, çevirme veya kırpma gibi işlemler uygular bu sayede yeni resimler türetilmiş olur. Bu türetmeler sonucunda eğitim verimiz çeşitlenir, sayısı bir hayli artar ve ağ tıpatıp aynı resim bulamaz. Bu sayede az bir eğitim verisiyle iyi bir ağ kurmak mümkün oluyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 0-255 olan pixel değerlerini 0-1 arasına sığacak şekilde scale eder\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('data/CNN/training_set',\n",
    "        target_size=(64, 64), # resim input shape ile aynı\n",
    "        batch_size=32,\n",
    "        class_mode='binary') # iki sınıfımız var diye binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('data/CNN/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 2172s 272ms/step - loss: 0.4170 - acc: 0.7999 - val_loss: 0.6700 - val_acc: 0.7605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4ff49bb70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eğitim 1 epoch için 35dk sürdü\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000, # kaç tane eğitim verimiz varsa onu yazıyoruz\n",
    "        epochs=1, # 1 epoch hiç iyi değil ama öbür türlü de saatler alıyor, normali 25ten başlamalı\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000) # test verisi sayısı\n",
    "# val'lı ifadeler test verisinin sonuçları"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli İyileştirmek - Daha Derin Bir Ağ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çıkan sonuç %76'larda. Peki %80'i nasıl geçirebiliriz, yani nasıl daha iyi hale getirebiliriz? Daha derin bir sinir ağı modelleyerek tabiki. Bunu yaparken de Convolution katmanını çoğaltıp bir tane daha fully connected layer yapabiliriz. Bu işlemi overfitting olduğunu gördüğümüz durumlarda da gerçekleştirebiliriz, böylece overfittinge de çözüm olur, test ile train accuracilerini daha derin bir ağ birbirlerine yakınlaştıracaktır. Daha da iyi sonuçlar için resimlerin input_shape'leri büyütülebilir(pixellerden daha fazla bilgi alabilmek için), daha da fazla derin katman eklenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daha derin bir ağ için Convolution katmanını çoğalttık ama ilk katmanda kendisine resim verisi gelirken ikinci katmanda kendisine pool edilmiş resim mapleri geliyor. Bunun için input_shape katmanını kaldırıyoruz çünkü elimizde işlenmiş mapler olacak ve buna gerek yok. Daha da iyi sonuçlar istersek 3. bir Convolution katmanı ekleriz ve mesela onun feature maplerinin boyutunu 32 değil de 64 belirleriz, bu sonuçları iyileştirecek-geliştirecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation = \"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Convolution2D(32, (3, 3), activation = \"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "\n",
    "\n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "classifier.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 1714s 214ms/step - loss: 0.3846 - acc: 0.8185 - val_loss: 0.6028 - val_acc: 0.7795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16b3355d828>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veri alma işlemlerini tekrarlamak yerine sadece ağı başlatacak kodu alıyorum\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000,\n",
    "        epochs=1,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000)\n",
    "# val'lı ifadeler test verisinin sonuçları"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk ağda train ile test accuracileri arasında %4 fark vardı, şimdikinde ise %2.5, ve accuraciler artmış durumda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img(\"data/CNN/single_prediction/cat_or_dog_1.jpg\", target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "# resme dördüncü bir boyut eklemek gerekiyor hata almamak için\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "result = classifier.predict(test_image)\n",
    "print(training_set.class_indices)\n",
    "print(result[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
