{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325.25]\n",
      " [331.27]\n",
      " [329.83]\n",
      " ...\n",
      " [793.7 ]\n",
      " [783.33]\n",
      " [782.75]]\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset_train = pd.read_csv(\"data/RNN - LSTM/Google_Stock_Price_Train.csv\")\n",
    "# bütün satırlardaki 1:2 sütunlarını al, yani sınıfı aldık böyle for ile tek tek gezmek yerine\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08581368]\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_scaled_set = sc.fit_transform(training_set)\n",
    "print(training_scaled_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a datastructure with 60 timesteps and 1 output</b><br>\n",
    "Bu ne demek? Belirlenen timestepsler short term memorynin bir veriyi öğrenirken daha önceki verileri bilgi olarak kullandığı için \"bir önceki kaç veriye bakarak yeni bilgiyi öğreniyim\" sorusunun cevabıdır. Yani burada 60 timesteps yaptığımız için ağa bir önceki 60 veriye dayanarak kendini eğit diyoruz. Eğer bu sayıyı fazla verirsek overfitting olur, az verirsek kötü bir ağ olur. İdeal sayıyı belirleyebilmek lazımdır. 1 outputun sebebi de şu, veri setimizdeki bilgilere baktığımızda verilerde tarih var, zamana göre değişimler gerçekleşiyor ve biz daha önceki değişimlere bakarak gelecek veriler(test verisi) hakkında tahminde bulunacak bir ağ oluşturacağız. Ağa dediğimiz şey ise şu \"bir önceki 60 veriye dayanarak 1 sonuç verecek şekilde programlan\", buna göre 60 günlük değişim göz önüne alınarak gelecek günlerdeki sonuçlar tahmin edilebilir.<br><br>\n",
    "Şimdi kodlarla yapacağımız şey ise bunu ağa uygun hale getirmek. Train verimize 60 günlük verileri tek bir veriymiş gibi ekleyeceğiz ve sınıf olarak 61. günün trendini ekleyeceğiz. Bütün verileri böyle eklediğimiz zaman 60 günün sonrasında olabilecek trendi tahmin edebilen bir ağ oluşacaktır. Kıpkısaca stok pricenin Open isimli sütunlarının verilerini aldık ve zamana göre değişimleri bir anlam ifade edecek şekilde 60 günlük Open verilerini sıraya dizip veri olarak alıp 61. gündeki Open verisini tahmin edeceğiz. Ağ 60 günlük değişimlerin 61. güne etkisini tahmin edebilecek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08581368 0.09701243 0.09433366 0.09156187 0.07984225 0.0643277\n",
      " 0.0585423  0.06568569 0.06109085 0.06639259 0.0614257  0.07474514\n",
      " 0.02797827 0.02379269 0.02409033 0.0159238  0.01078949 0.00967334\n",
      " 0.01642607 0.02100231 0.02280676 0.02273235 0.02810849 0.03212665\n",
      " 0.0433812  0.04475779 0.04790163 0.0440695  0.04648783 0.04745517\n",
      " 0.04873875 0.03936305 0.04137213 0.04034898 0.04784582 0.04325099\n",
      " 0.04356723 0.04286033 0.04602277 0.05398467 0.05738894 0.05714711\n",
      " 0.05569611 0.04421832 0.04514845 0.04605997 0.04412531 0.03675869\n",
      " 0.04486941 0.05065481 0.05214302 0.05612397 0.05818885 0.06540665\n",
      " 0.06882953 0.07243843 0.07993526 0.07846566 0.08034452 0.08497656] [0.08627874]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(60, len(training_set)):\n",
    "    X_train.append(training_scaled_set[i-60 : i, 0])\n",
    "    Y_train.append(training_scaled_set[i])\n",
    "    # her bir veri [] liste içinde olduğundan ,0 koymak onları listeden çıkartıp bir veri olarak ekleyecektir\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "print(X_train[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198 60\n"
     ]
    }
   ],
   "source": [
    "# Reshaping, RNN anlayacağı şekle sokuyoruz\n",
    "# (X_train, (numOfOpenStockPrice, timesteps, numberOfIndıcators(predictors-features)))\n",
    "print(X_train.shape[0], X_train.shape[1])\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilazing the RNN - stacked LSTM\n",
    "# continuous, devam eden değerlere göre output tahmin edceğimiz için öylesine regressor dedik\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "units = lstm memory üniteleri, yani nöronlar. Bir kaç lstm katmanından oluşan derin bir ağ yapacağız, ancak units sayısını yüksek tutarak bunu daha da derinleştirmemiz mümkün olacaktır. Stock price gibi komplex bir veri için iyi bir derinlik ve çok sayıda nörona ihtiyacımız olacaktır. 50 olarak seçiyoruz ki yüksek derinliğe ulaşabilelim. Eğer sayıyı düşük tutarsak yükselen ve düşen trendleri doğru tahmin etmek çok zorlaşacaktır.<br>\n",
    "return_sequences default olarak False bir değerdir ve bu lstm katmanından sonra bir lstm katmanı olmayacağı anlamına gelir. Ancak biz birkaç tane lstm katmanı oluşturacağımızdan, kendisinden sonra lstm katmanı gelecek katmanlara bu değeri True olarak veriyoruz.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lstm layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "# adding dropout regularization, overfittingi engellemek için\n",
    "# 0.2 = %20 of the neurons will be ignored during the forward and back propagation\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSprop genelde rnn de kullanılan iyi sonuç veren bir optimizer ama adam kullanıyoruz.<br>\n",
    "Başka algoritmalar keras.documentationda bulunabilir TFOptimizer, Nadam felan.<br>\n",
    "loss fonksiyonu olarak mean_squared_error kullanyoruz çünkü artık sınıflandırma yapmıyoruz regresyon işlemi yapıyoruz crosentropy kullanmak olmaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the rnn\n",
    "regressor.compile(optimizer = \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu sayıda veri için bu epoch sayısı iyi sonuç vermiştir. 25, 50 de denenebilir ancak bunun kadar iyi vermez. Batch size de 32 uygun görüşmüştür, her 32 verilik kümelerle eğitim yapıp loss fonksiyonuna göre back propagation yapılıp ağırlıklar güncelleniyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1198/1198 [==============================] - 6s 5ms/step - loss: 0.0471\n",
      "Epoch 2/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0063\n",
      "Epoch 3/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0053\n",
      "Epoch 4/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0047\n",
      "Epoch 5/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0045\n",
      "Epoch 6/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0047\n",
      "Epoch 7/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0049\n",
      "Epoch 8/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0041\n",
      "Epoch 9/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0042\n",
      "Epoch 10/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0043\n",
      "Epoch 11/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0043\n",
      "Epoch 12/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 13/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0040\n",
      "Epoch 14/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0039\n",
      "Epoch 15/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0036\n",
      "Epoch 16/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 17/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 18/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0035\n",
      "Epoch 19/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 20/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 21/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0032\n",
      "Epoch 22/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 23/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0032\n",
      "Epoch 24/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0032\n",
      "Epoch 25/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0030\n",
      "Epoch 26/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 27/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0028\n",
      "Epoch 28/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 29/100\n",
      "1198/1198 [==============================] - 4s 4ms/step - loss: 0.0032\n",
      "Epoch 30/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0033\n",
      "Epoch 31/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0035\n",
      "Epoch 32/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0030\n",
      "Epoch 33/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 34/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0031\n",
      "Epoch 35/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0032\n",
      "Epoch 36/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 37/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0026\n",
      "Epoch 38/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0027\n",
      "Epoch 39/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0031\n",
      "Epoch 40/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0026\n",
      "Epoch 41/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0027\n",
      "Epoch 42/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0024\n",
      "Epoch 43/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0027\n",
      "Epoch 44/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0029\n",
      "Epoch 45/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0025\n",
      "Epoch 46/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0025\n",
      "Epoch 47/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0024\n",
      "Epoch 48/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0031\n",
      "Epoch 49/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0026\n",
      "Epoch 50/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0023\n",
      "Epoch 51/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0023\n",
      "Epoch 52/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0023\n",
      "Epoch 53/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0021\n",
      "Epoch 54/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0023\n",
      "Epoch 55/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0022\n",
      "Epoch 56/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0023\n",
      "Epoch 57/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0027\n",
      "Epoch 58/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0022\n",
      "Epoch 59/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0020\n",
      "Epoch 60/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0021\n",
      "Epoch 61/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0021\n",
      "Epoch 62/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0025\n",
      "Epoch 63/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0021\n",
      "Epoch 64/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0018\n",
      "Epoch 65/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0022A: 0s - loss: 0.\n",
      "Epoch 66/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0020\n",
      "Epoch 67/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0022\n",
      "Epoch 68/100\n",
      "1198/1198 [==============================] - 3s 3ms/step - loss: 0.0019\n",
      "Epoch 69/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0021\n",
      "Epoch 70/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 71/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 72/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0021\n",
      "Epoch 73/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0020\n",
      "Epoch 74/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 75/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0019\n",
      "Epoch 76/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0019\n",
      "Epoch 77/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0018\n",
      "Epoch 78/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0018A: 0s - loss: 0.00\n",
      "Epoch 79/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n",
      "Epoch 80/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 81/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 84/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 86/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0017\n",
      "Epoch 88/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n",
      "Epoch 91/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 92/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0014\n",
      "Epoch 93/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 94/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 95/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0018\n",
      "Epoch 98/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n",
      "Epoch 99/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n",
      "Epoch 100/100\n",
      "1198/1198 [==============================] - 4s 3ms/step - loss: 0.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e1f0630eb8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, Y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions and Visualising the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the stockprice of 2017 (20 taneler)\n",
    "dataset_test = pd.read_csv(\"data/RNN - LSTM/Google_Stock_Price_Test.csv\")\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set, aslında train setin devamı olan verilerden oluşuyor. Yani test setteki ilk veriyi tahmin edebilmek için, kendisinden önceki 60 veriyi almamız lazım ki ilk test verisinden önceki 60 veri, train setindeki son 60 veridir. Böylece test verisini 20 sıralı bir veri olacak şekilde traindeki verilerle birleştirmemiz gerekiyor. Training_Set'i normalize etmiştik ama test seti normalize etmemiştik, biz şimdi test ve train verilerini birleştirerek test verileri oluşturacağız ve bu yüzden bu test verisini de normalize etmemiz gerekecek ancak bu durumda çıkması gereken sonuçlar da normalize edilmiş olacak bu yüzden normalize edilmiş çıktıları tekrar eski hallerine döndürmemiz gerekecek. Ve tabiki görsellik katıp karşılaştırma yapmak adına orjinal test verisini saklamamız, değiştirmememiz gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.25  <->  778.81  <->  0    325.25\n",
      "0    778.81\n",
      "Name: Open, dtype: float64\n",
      "1258  <->  20  <->  1278\n"
     ]
    }
   ],
   "source": [
    "# train ve testten genel bir veri oluşturuyoruz \"Open\" sütun ismi\n",
    "dataset_total = pd.concat((dataset_train[\"Open\"], dataset_test[\"Open\"]), axis = 0)\n",
    "print(dataset_train[\"Open\"][0], \" <-> \", dataset_test[\"Open\"][0], \" <-> \", dataset_total[0])\n",
    "print(len(dataset_train), \" <-> \", len(dataset_test), \" <-> \", len(dataset_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[779.   779.66]\n",
      "[[779.  ]\n",
      " [779.66]]\n",
      "[[0.9299055 ]\n",
      " [0.93113327]]\n"
     ]
    }
   ],
   "source": [
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "print(inputs[:2])\n",
    "\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "print(inputs[:2])\n",
    "\n",
    "inputs = sc.transform(inputs)\n",
    "print(inputs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(60, len(inputs)):\n",
    "    X_test.append(inputs[i-60 : i, 0])\n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9111153 ]\n",
      " [0.9067572 ]\n",
      " [0.90572494]\n",
      " [0.9072496 ]\n",
      " [0.9123984 ]]\n",
      "[[768.8991 ]\n",
      " [766.5564 ]\n",
      " [766.0015 ]\n",
      " [766.8211 ]\n",
      " [769.58887]]\n"
     ]
    }
   ],
   "source": [
    "predicted_stock_prices = regressor.predict(X_test)\n",
    "# normalize halde tahmin edilmiş sonuçları tersine çeviriyoruz yani normalize->to->real shape\n",
    "print(predicted_stock_prices[0:5])\n",
    "predicted_stock_prices = sc.inverse_transform(predicted_stock_prices)\n",
    "print(predicted_stock_prices[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd0VOXWwOHfpknvqDSBC0gLJEJEihQFAQmCSlDsYgHFdu36qajXrigIFkRBRFERxI6AUiwgalBUpFcJzdB7zf7+eE/IECbJhGRyJsl+1jorM2fOzNlTMnveLqqKMcYYk1YhvwMwxhgTmSxBGGOMCcoShDHGmKAsQRhjjAnKEoQxxpigLEEYY4wJyhKE8Y2IPCYi7/kdR0ZEZLWIdA7TY/8tIh3D8djhIiIqIvW8yyNE5JETfJzdIvKfnI3O5DRLEAYR6SsiP4vIHhH517s8UETE79jSIyJni8gcEdkhIltFZLaInOnddq2I/OhDTOq9hrtFZJ2IvCQihdM7XlWbqOqsHI5hlojs92LYLCKTRKRqTp4jharepKpPhBjTDWnuW1pVV4YjLpNzLEEUcCJyN/Ay8AJwKnAKcBPQFijmY2jpEpGywJfAcKAiUB14HDjgZ1yeaFUtDXQCLgduTHuAiBQJcwy3ejGcDpQHhgQ7KKPkZQxYgijQRKQc8D9goKpOVNVd6vyuqleo6oGU40RkrIgkicgaEXlYRAp5txXyrq/xSh9jvcdNOcfV3m1bROSRjKpsRKSVVyrYLiJ/ZFD9cjqAqn6gqkdUdZ+qTlPVP0WkETACaO39it6e2XPwbr9RRBaJyC4RWSgizYPE11BEVolI38xeW1VdDPwARHn3XS0i94vIn8AeESkS+FqISGER+T8RWeHFME9Eagac9xuvpLRERC7J7PxeDFuBjwNiGCMir4vIZBHZA5wjIieJyGAR+UdENnnVRiUCnvO9IrJBRNaLyHVpXo8xIvJkwPVeIjJfRHZ6z6ObiDwFtANe8d6PV7xjA6uqMvp8XSsiP3oxbvNe//NDef4mB6iqbQV0A7oBh4EimRw3FvgMKAPUBpYC13u3XQcsB/4DlAYmAe96tzUGdgNn40ojg4FDQGfv9seA97zL1YEtQHfcD5fzvOtVgsRT1rvtHeB8oEKa268FfszCc+gDrAPOBASoB9TyblsNdAaaA/8APTJ4nRSoF/DcNwacYzUwH6gJlAh8bO/yvcBfQAMvhmigElAKWAv0A4p4cWwGmqQTwyzgBu9yZWBGwPsxBtiBKx0WAooDQ4HPcSWxMsAXwDMBn49NuARTCng/zXMcAzzpXW7pPfZ53mNXBxqmjSmd1yqj9+Za3GfmRqAwcDOwHhC//38KwuZ7ALb5+ObDlcDGNPvmANuBfUB775/yANA44JgBwCzv8nRcCSTltgbeP3QRYBDwQcBtJYGDBE8Q96d8kQUcPxW4Jp3YG3lfUIm4JPc5cIp327UEJIgQnsNU4I50zrMaV32VCJyTyeupwE5gG7ACeBIoFPA41wV57JTXYgnQK8hjXgr8kGbfG8Cj6cQwC9jrvYfrgHF4SdZ7vcYGHCvAHqBuwL7WwCrv8mjg2YDbTif9BPEGMCSDmIImiBDem2uB5Wk+Qwqc6vf/T0HYwl0XaiLbFqCyiBRR1cMAqtoGQEQScb8EK+N+/a8JuN8a3C9EgGpBbiuCa8uohvv1i/fYe0VkSzqx1AL6iMgFAfuKAjODHayqi3BfHohIQ+A93K/hy4IcntlzqIn7Qk/PTcB3qho0ljSaq+rydG5bm87+jGKoBZyVUlXmKQK8m8Fj3a6qb4UQQxXcF+48Se2PILgvbXDv37yA4wNfv7RqApMzuD09mb034EpiwNHPELjSqgkza4Mo2H7C/XrrlcExm3ElgloB+07D/ToFV9xPe9thXNXEBqBGyg1e3XaldM6zFleCKB+wlVLVZzN7Eurq+8fg1bXjfmFm5TmsBepmcIqbgNNEJGhjbxZkNHVyejGsxSWnwNeltKrenAMxbMaVFJsEPHY5dQ3c4N6/mgHHn3YC8ac9Z1qZvTfGR5YgCjBV3Y6rPnlNROJFpLTX6ByDq3NGVY8AHwFPiUgZEakF3IX7xQ7wAXCniNQRkdLA08B4r0QyEbhARNqISDHvXOl1nX3PO7ar12BbXEQ6ikiNtAd6jbZ3p9zmNeZeBsz1DtkE1PDOGcpzeAu4R0RaiFPPOybFLlx9fHsRyTRhnaC3gCdEpL4XQzMRqYTrrXW6iFwlIkW97UyvMT5bVDUZeBMYIiInA4hIdRHp6h3yEXCtiDQWkZLAoxk83Cign4h08j5D1b2SHbj3I+iYhxDeG+MjSxAFnKo+j/uHvA/4F/fP/AauTWCOd9htuLrqlcCPuMbK0d5to3HVHd8Dq4D93vGo6t/e5Q9xv0Z3eec4rjuqqq7FlWT+D0jC/SK9l+Cf0V3AWcDPXm+cucAC4G7v9hnA38BGEdmc2XNQ1QnAU96+XcCnuEbbwPi24xpgzxeRTPv+n4CXcF+U03DtGKNwjdm7gC5AX1xpbSPwHHBSDp33flwng7kishP4FteOhKp+jau2m+EdMyO9B1HVX3AN6UNwjdXfkVoqeBmI93ohDQty94w+X8ZH4jX8GBN2XgljO1BfVVf5HY8xJmNWgjBhJSIXiEhJESmF6+b6F673jjEmwlmCMOHWC1c1sh6oD/RVK7YakydYFZMxxpigrARhjDEmqDw9UK5y5cpau3Ztv8Mwxpg8Zd68eZtVtUpmx4U1QYjIncANuIEyfwH9VHW/d9tw73pp7/pJuDlZWuBG+F6qqqszevzatWuTkJAQvidgjDH5kIhkNCr+qLBVMYlIdeB2IFZVo3DD9/t6t8XipiEOdD2wTVXr4fpSPxeu2IwxxmQu3G0QRYAS4ua/LwmsFzcH/Qu4gVmBeuFm5wQ3AreTSOQuWGOMMfld2BKEqq7D9Xv/BzeKdoeqTgNuBT5X1Q1p7lIdbyIxb5qGHQSZt0dE+otIgogkJCUlhSt8Y4wp8MLWBiEiFXClgjq40bMTRORq3Nz7HYPdJci+4/rgqupIYCRAbGzscbcfOnSIxMRE9u/ff+LBG5OJ4sWLU6NGDYoWLep3KMaETTgbqTvj5pVPAhCRSbjJ2koAy73ao5Iistxrd0jEzRyZ6FVJlQO2ZvWkiYmJlClThtq1a2M1VCYcVJUtW7aQmJhInTp1/A7HmLAJZxvEP0Arb5oFwa3R+5KqnqqqtVW1NrDXSw7gFny5xrscD8w4kRG3+/fvp1KlSpYcTNiICJUqVbJSqsn3wlaCUNWfRWQi8BtufYDf8aqG0jEKeFdEluNKDpmu+5seSw4m3OwzZgqCsI6DUNVHyWAO+YCFSfDGR/QJZzzGGIMqvPsuNGkCLVr4HU1Es6k2wqBw4cLExMQQFRXFBRdcwPbt2zO/Uzpq167N5s2bj9u/e/dubr75ZurWrcsZZ5xBixYtePPNN7MTdlAdO3bM0mDEuXPnctZZZxETE0OjRo147LHHAJg1axZz5szJ+M7pWL16NVFRUZkeU6JECWJiYmjcuDE33XQTycnJQY9t06bNCcVh8okxY+CaayA2Fi69FJYu9TuiiGUJIgxKlCjB/PnzWbBgARUrVuTVV1/N8XPccMMNVKhQgWXLlvH7778zZcoUtm7Ncpt+jrvmmmsYOXLk0ed/ySWXANlLEKGqW7cu8+fP588//2ThwoV8+umnx9x+5MgRgLDHYSLY8uVw223QsSMMGgRffQWNG8OAAbB+vd/RRRxLEGHWunVr1q1LXV73hRde4Mwzz6RZs2Y8+mhq7duFF15IixYtaNKkCSNHZtRUAytWrOCXX37hySefpFAh9xZWqVKF+++/H3C9bO69916ioqJo2rQp48ePz3B/cnIyAwcOpEmTJvTo0YPu3bszceLE4847bdo0WrduTfPmzenTpw+7d+8+7ph///2XqlWrAq4k1bhxY1avXs2IESMYMmQIMTEx/PDDD6xZs4ZOnTrRrFkzOnXqxD///APApk2buOiii4iOjiY6Ovq4L/OVK1dyxhln8Ouvv6b7+hQpUoQ2bdqwfPlyZs2axTnnnMPll19O06ZNAShdOnW9++eff56mTZsSHR3NAw88cPT17datGy1atKBdu3YsXrw4w/fD5BGHDsEVV0CxYjB2LDz+OKxYAQMHwttvQ7168MADsG2b35FGDlXNs1uLFi00rYULF6ZeueMO1Q4dcna7447jzplWqVKlVFX18OHDGh8fr19//bWqqk6dOlVvvPFGTU5O1iNHjmhcXJx+9913qqq6ZcsWVVXdu3evNmnSRDdv3qyqqrVq1dKkpKRjHv+zzz7TCy+8MN3zT5w4UTt37qyHDx/WjRs3as2aNXX9+vXp7p8wYYKef/75euTIEd2wYYOWL19eJ0yYoKqqHTp00F9//VWTkpK0Xbt2unv3blVVffbZZ/Xxxx8/7tyPP/64li9fXi+88EIdMWKE7tu3T1VVH330UX3hhReOHtejRw8dM2aMqqqOGjVKe/Xqpaqql1xyiQ4ZMuTo67d9+3ZdtWqVNmnSRBcvXqwxMTH6+++/H3felGNUVffs2aOxsbE6efJknTlzppYsWVJXrlx53PszefJkbd26te7Zs+eY9+Dcc8/VpUuXqqrq3Llz9Zxzzgn6Oh/zWTOR7+GHVUH1o4+Ov23lStUrr1QVUS1fXvXZZ1W9z0V+BCRoCN+xVoIIg3379hETE0OlSpXYunUr5513HuB+gU+bNo0zzjiD5s2bs3jxYpYtWwbAsGHDiI6OplWrVqxdu/bo/lA89dRTxMTEUK1aNQB+/PFHLrvsMgoXLswpp5xChw4d+PXXXzPc36dPHwoVKsSpp57KOeecc9w55s6dy8KFC2nbti0xMTG88847rFlz/HxfgwYNIiEhgS5duvD+++/TrVu3oDH/9NNPXH755QBcddVV/PjjjwDMmDGDm2++GXAlkHLlygGQlJREr169eO+994iJiQn6mCtWrCAmJoa2bdsSFxfH+eefD0DLli2Djlf49ttv6devHyVLlgSgYsWK7N69mzlz5tCnTx9iYmIYMGAAGzakHfRv8pwffoCnn4Z+/aBPkL4wdeq4huv586FtW1eSqF8fRo50JY8CKk9P952poUN9OW1KG8SOHTvo0aMHr776KrfffjuqyoMPPsiAAQOOOX7WrFl8++23/PTTT5QsWZKOHTtm2Me+cePG/PHHHyQnJ1OoUCEeeughHnrooaNVJ5rO8JGs7k97zHnnnccHH3yQ6bF169bl5ptv5sYbb6RKlSps2bIl0/tk1m20XLly1KxZk9mzZ9OkSZN0zzt//vzj9pcqVSro8ap63HmTk5MpX7580McxedT27XDllS4JvPxyxsc2awZffukSyoMPuraJwYPhySchPh4KFazf1AXr2eaycuXKMWzYMAYPHsyhQ4fo2rUro0ePPlp3v27dOv7991927NhBhQoVKFmyJIsXL2bu3LkZPm69evWIjY3l4YcfPtrwun///qNf9O3bt2f8+PEcOXKEpKQkvv/+e1q2bJnu/rPPPpuPP/6Y5ORkNm3axKxZs447Z6tWrZg9ezbLly8HYO/evSwN0vvjq6++OhrHsmXLKFy4MOXLl6dMmTLs2rXr6HFt2rThww8/BGDcuHGcffbZAHTq1InXX38dcI3KO3fuBKBYsWJ8+umnjB07lvfffz+0NyATXbp0YfTo0ezduxeArVu3UrZsWerUqcOECRMAl0T++OOPHDmf8cktt8C6dTBuHJQpE9p92rVzSeLzz+Gkk1xvp5Yt4ZtvwhtrpAmlHipSt0zbIHySUsedokePHjp27FhVVR06dKhGRUVpVFSUtmrVSpcvX6779+/Xbt26adOmTTU+Pl47dOigM2fOVNXgbRCqqjt27ND+/ftr7dq1tXnz5tq2bVsdPny4qqomJyfrPffco02aNNGoqCj98MMPM9x/5MgRHTBggDZq1Eh79eql3bp102nTpqlqahuEqur06dM1NjZWmzZtqk2bNtXPPvvsuLguvfRSrV+/vkZHR2uLFi10ypQpqqq6ZMkSbdq0qUZHR+v333+vq1at0nPOOUebNm2q5557rq5Zs0ZVVTdu3Kg9e/bUqKgojY6O1jlz5hzTvrBt2zaNjY3VTz/99JjzBh4TaObMmRoXF5fu+/PMM89oo0aNNDo6Wh988EFVVV25cqV27dpVmzVrpo0aNQra1qIaGZ81k4n33nPtDk88ceKPcfiw6tixqrVqucfq1En1l19yLEQ/EGIbRJ5ekzo2NlbT9tFftGgRjRo18imivGv37t2ULl2aLVu20LJlS2bPns2pp57qd1gRzT5rEW71aoiOdtVGs2ZB4cLZe7wDB+CNN1x1U1KSa7O48sqciDTXicg8VY3N7DirYjIA9OjRg5iYGNq1a8cjjzxiycHkbYcPp355v/tu9pMDuKqm2293XWMbNHAD7vK5/N1IbUIWrN3BmDzr2Wdh9mx47z3I6XXry5SBnj1dJ5hdu0Jv18iDrARhjMlffv4ZHnsMLr/cDYwLh7g41/3122/D8/gRwhKEMSb/2LXLJYUaNSAMU9wc1aYNlC0LkyeH7xwRwKqYjDH5xx13wKpVrlG6fPnwnadoUejSxSUIVcin079bCcIYkz9MmODmVPq//3PjGMItLs5N8Pfnn+E/l08sQYRB4HTfffr0OToQ60TMmjWLHj16APD555/z7LPPpnvs9u3bee2117J8jscee4zBgwcft3/JkiV07Njx6NTd/fv3B2D+/PlMzkbROnCyvPSE+hp27949W9Opm3wiMdGNem7Z0s3SmhtSppH56qvcOZ8PLEGEQeB038WKFWPEiBHH3K6q6a5VkJGePXsenXE0mBNNEOm5/fbbufPOO5k/fz6LFi3itttuA7KfIEIR6ms4efJkyoezKsFEvuRkuPpqOHjQjZYuWjR3znvqqW7BoXzcDmEJIszatWvH8uXLWb16NY0aNWLgwIE0b96ctWvXpjt99pQpU2jYsCFnn302kyZNOvpYY8aM4dZbbwWCT4v9wAMPHJ2w7t577wXSn178qaeeokGDBnTu3JklS5YEjX3Dhg3UqFHj6PWmTZty8OBBBg0axPjx44mJiWH8+PFs3bqVCy+8kGbNmtGqVSv+9Ircu3fvpl+/fjRt2pRmzZrx8ccfH/P4mzdvpnXr1nyVyS+wjF7DwAWVxo4dS7NmzYiOjuaqq64C3CR/vXv35swzz+TMM89k9uzZmb9pJm958UWYOROGD3dTduem7t3hp58gAtZiCYtQhltH6pbZVBs+zfZ9dCqHQ4cOac+ePfW1117TVatWqYjoTz/9pKqa7vTZ+/bt0xo1aujSpUs1OTlZ+/Tpc3SqiLfffltvueUWVc14WuwU6U0vnpCQoFFRUbpnzx7dsWOH1q1b95ipuFOMHj1ay5Ytq926ddOXXnpJt23bdlwcqqq33nqrPvbYY6rqpuOIjo5WVdX77rtP7wh4wbZu3Xr09dm4caO2bNny6JQeJ/IaqqZORbJgwQI9/fTTj05LkjJ192WXXaY//PCDqqquWbNGGzZsmP4bl0U21UYEmDdPtWhR1fh41eTk3D//3Llu+o3338/9c2cDIU61EdZeTCJyJ3ADoMBfQD/gVSAWEGApcK2q7haRk4CxQAtgC3Cpqq4OZ3zhkjLdN7hfv9dffz3r16+nVq1atGrVCjh2+myAgwcP0rp1axYvXkydOnWoX78+AFdeeWXQBYRmzJjB2LFjgdRpsbelWegkcHpxcL/oly1bxq5du7jooouOTnPds2fPoM+jX79+dO3alSlTpvDZZ5/xxhtvBJ247scffzxaOjj33HPZsmULO3bs4Ntvvz06IR9AhQoVADh06BCdOnXi1VdfpUOHDif8GqZ9PeLj46lcuTLgpu4GN6X3woULjx63c+dOdu3aRZl8PLipwNi71411OPlkNwWGHz2JYmOhcmVXzXTZZbl//jALW4IQkerA7UBjVd0nIh8BfYE7VXWnd8xLwK3As8D1wDZVrScifYHngEuzE4NPs30frT9PK3DaaU1n+uz58+dnOvV1qFSDTy8+dOjQkM9RrVo1rrvuOq677jqioqJYsGBB0POkJSJBp9MGt+JbixYtmDp1aroJIpTXMG0Mwc6VnJzMTz/9RIkSJYLez+Rhd9/t1pP+9lvwfhDkusKFXWP1lClw5EjOTOkRQcLdBlEEKCEiRYCSwPqA5CBACVzpAqAX8I53eSLQSXLqmzICpTd9dsOGDVm1ahUrVqwASHf9hWDTYqedUju96cXbt2/PJ598wr59+9i1axdffPFF0HNMmTKFQ95iKRs3bmTLli1Ur179uPO0b9+ecePGAa7XVeXKlSlbtixdunThlVdeOXpcSglHRBg9ejSLFy/OsFdWVnTq1ImPPvro6NoTKetzp43B1nnIJz7/HEaMgHvugXPP9TeWuDjYvBkyWAY3rwpbglDVdcBg4B9gA7BDVacBiMjbwEagITDcu0t1YK1338PADqBS2scVkf4ikiAiCUlJSeEKP+yqVKnCmDFjuOyyy4427i5evJjixYszcuRI4uLiOPvss6lVq1bQ+7/88svMnDmTpk2b0qJFC/7++28qVapE27ZtiYqK4t5776VLly5cfvnltG7dmqZNmxIfH8+uXbto3rw5l156KTExMfTu3Zt26fQZnzZtGlFRUURHR9O1a1deeOGFoyvOLVy48Ggj9WOPPUZCQgLNmjXjgQce4J13XJ5/+OGH2bZt29HHmDlz5tHHLly4MB9++CEzZ87MkZ5XTZo04aGHHqJDhw5ER0dz1113AW6lvpTYGjdufFxvKJMHrV0L118PZ5wBTzzhdzRuwFyhQvmyN1PYpvsWkQrAx7hqou3ABGCiqr7n3V4Ylxx+VdW3ReRvoKuqJnq3rwBaqmq6y5HZdN/GT/ZZ88H+/W4Q3JIl7hd7gwZ+R+ScfbaLLc33UaSKhOm+OwOrVDVJVQ8Bk4A2KTeq6hFgPNDb25UI1ATwqqTKAfm075gxJstUYeBA9yX83nuRkxzAdXedNw82bvQ7khwVzgTxD9BKREp6bQmdgEUiUg+OtkFcACz2jv8cuMa7HA/M0HAVb4wxec+IEW4qjUGD3HTbkSQuzv39+mt/48hh4WyD+BnX2PwbrotrIWAk8I6I/OXtqwr8z7vLKKCSiCwH7gLSHzKc+bmzEbkxmbPPWC6bPdst1hMXBwEDPiNGs2ZQrVq+a4cI6zgIVX0USPtutk3n2P1An+yes3jx4mzZsoVKlSrlWHdRYwKpKlu2bKF48eJ+h1IwrF8P8fFu4Z/33nMNwpFGxFUzffSRWycit6b7CLN8N913jRo1SExMJC/3cDKRr3jx4sdMQ2LC5OBBlxx27XLjHSJ53q24OHjrLVfa6djR72hyRL5LEEWLFqVOnTp+h2GMyQl33OHmOpowAZo08TuajHXq5EoOkyfnmwQRgWU1Y4wBRo1yDdP33+9KEZGuTBlo3z5ftUNYgjDGRJ5ffnFdWrt0gaee8jua0MXFwd9/w5o1fkeSIyxBGGMiy6ZNcPHFrlfQ++/nrfmNund3f/NJKcIShDEmchw6BJdc4tZX+OQTqHTcbDuR7fTT4T//sQRhjDE57p574PvvXW8gb7r3PCWlu+v06W7qjTzOEoQxJjK8+y4MGwZ33unWecir4uJg3z6YNcvvSLLNEoQxxn+//Qb9+7vuoc8/73c02dOhA5QokS+qmSxBGGP8tXkzXHQRVKkC48dDkTw+PKtECbdGxVdfuQkG8zBLEMYY/xw+DH37up5Lkya55UPzg7g4WLnSrXiXh1mCMMb458EHXYPuiBFufef84vzz3d88Xs1kCcIY44/x42HwYDcg7tpr/Y4mZ9WuDY0bW4Iwxpgs+/NPuO46aNsWhgzxO5rw6N4dvvvOTTSYR1mCMMbkrgMH3EjpcuVg4kQoVszviMIjLs4N/Js+3e9ITpglCGNM7vrsM1ixAt58E0491e9owqdtWzeBXx6uZrIEYYzJXaNGwWmnpTbk5ldFi7rJBidPzrPdXS1BGGNyz5o18M030K9fZK4Ml9Pi4mDdOtfmkgeF9R0SkTtF5G8RWSAiH4hIcREZJyJLvH2jRaSod6yIyDARWS4if4pI83DGZozxwZgx7m+/fr6GkWu6dXN/82g1U9gShIhUB24HYlU1CigM9AXGAQ2BpkAJ4AbvLucD9b2tP/B6uGIzxvggORnefhs6d4ZatfyOJndUrQrNm1uCSEcRoISIFAFKAutVdbJ6gF+AlIV9ewFjvZvmAuVFpGqY4zPG5Jbp010V0/XX+x1J7oqLgzlz3BTmeUzYEoSqrgMGA/8AG4Adqjot5XavaukqYIq3qzqwNuAhEr19xxCR/iKSICIJSUlJ4QrfGJPTRo2CihXhwgv9jiR3de/uSk/TpmV+bIQJZxVTBVypoA5QDSglIlcGHPIa8L2q/pBylyAPc1zTv6qOVNVYVY2tUqVKTodtjAmHLVvcAkBXXgknneR3NLnrzDPdwkd5sJopnFVMnYFVqpqkqoeASUAbABF5FKgC3BVwfCJQM+B6DWB9GOMzxuSWcePg4MGCV70EbsnUbt3g66/hyBG/o8mScCaIf4BWIlJSRAToBCwSkRuArsBlqpoccPznwNVeb6ZWuCqpDWGMzxiTG1Rd9VJsLDRr5nc0/oiLc9OaJyT4HUmWhLMN4mdgIvAb8Jd3rpHACOAU4CcRmS8ig7y7TAZWAsuBN4GB4YrNGJOL5s1z4wAKYukhRZcubtxHHqtmEs2jI/wAYmNjNSGPZWRjCpybb4Z33oENG9z8SwVV27aumu3XX/2OBBGZp6qZzq9eAIYyGmN8s3cvvP8+xMcX7OQArpopIQE2bvQ7kpBZgjDGhM/HH8POnQW7eilF9+7u75QpGR8XQSxBGGPCZ9QoqFcP2rf3OxL/RUdDtWp5qh3CEoQxJjyWL3cL5lx3HUiwYU4FjIgrRUyd6taJyAMsQRhjwmP0aNdz55pr/I4kcnTv7qrc5szxO5KQWIIwxuS8w4fdzK3du7tqFeN06uTWicgj1UyWIIwxOW8SyFQLAAAgAElEQVTKFNet1Rqnj1W2LLRrZwnCGFOAjRoFp5ziunaaY8XFwYIF8M8/fkeSKUsQxpictWkTfPklXH21q04xx0rp7vrVV/7GEQJLEMaYnDV2rGuDuO46vyOJTA0auK6/n37qdySZsgRhjMk5KRPztW0LDRv6HU1kEnEjy6dPd9OgRzBLEMaYnDNnDixZYo3TmYmPd1N/f/6535FkyBKEMSbnjBoFpUtDnz5+RxLZmjeH2rXdVCQRzBKEMSZn7NoFH30Effu6JGHSJwK9e7tlSHfs8DuadFmCMMbkjPHjYc8ea5wOVXy8m3Ljiy/8jiRdliCMMTlj1Cho1AhatfI7kryhZUuoXh0mTvQ7knRZgjDGZN/ChTB3rmucton5QlOokKtmmjLFVc9FIEsQxpjsGzUKihSBq67yO5K8JT4eDhyI2Kk3Mk0Q4lyZsna0iJwmIi3DH5oxJk84eNANjuvZE04+2e9o8pY2bdyUJBFazRRKCeI1oDVwmXd9F/BqKA8uIneKyN8iskBEPhCR4iJyq4gsFxEVkcoBx4qIDPNu+1NEmmf52Rhjct8XX8DmzTb24UQULgwXX+xKEHv3+h3NcUJJEGep6i3AfgBV3QYUy+xOIlIduB2IVdUooDDQF5gNdAbWpLnL+UB9b+sPvB7iczDG+GnUKNfY2rWr35HkTfHxLjlE4FKkoSSIQyJSGFAAEakCJIf4+EWAEiJSBCgJrFfV31V1dZBjewFj1ZkLlBeRqiGexxjjh8REt0Latde6X8Mm69q3h0qVIrKaKZQEMQz4BDhZRJ4CfgSezuxOqroOGAz8A2wAdqjqtAzuUh1YG3A90dt3DBHpLyIJIpKQlJQUQvjGmLAZMwaSk23sQ3YUKQIXXeRmwN2/3+9ojpFpglDVccB9wDO4L/oLVXVCZvcTkQq4UkEdoBpQSkSuzOguwU4fJJ6RqhqrqrFVqlTJLAxjTLgkJ7tlRc85B/7zH7+jydvi411X12++8TuSY4TSi6kVsE5VX1XVV4BEETkrhMfuDKxS1SRVPQRMAtpkcHwiUDPgeg1gfQjnMcb4YdYsWLXKGqdzwjnnQPnyEVfNFEoV0+vA7oDrewitAfkfoJWIlBQRAToBizI4/nPgaq83UytcldSGEM5jjPHDqFFQrpzrhWOyp1gx6NXLze568KDf0RwVSoIQVT1a1aOqybjG5wyp6s/AROA34C/vXCNF5HYRScSVEP4Ukbe8u0wGVgLLgTeBgVl5IiaXHTnidwTGT9u2uZlIr7gCSpTwO5r8IT4etm+HGTP8juSoUBLESu9Lvai33YH7Is+Uqj6qqg1VNUpVr1LVA6o6TFVrqGoRVa2mqjd4x6qq3qKqdVW1qaomZOeJmRz2778wYQLccgs0aeJ+8VxyCfz5p9+RnRg9rnnLZMX777sRwFa9lHPOOw/KlImoaibRTP5RRORkXE+mc3GNxtOB/6rqv+EPL2OxsbGakGB5JCySkuC771w986xZ8Pffbn+pUtCunZvLftw417B20UXwyCNwxhm5F9/27W5w1o4dqdvOncdez2jbu9c9lwoVoGJFt6Vczmxf2bIFZ76hAweCv8aPPOLWm/79d78jzF+uuMJ1G9640fVuChMRmaeqsZkdF0pV0b+4AW4mP9u8+diEsGCB21+qFJx9Nlx5JXTsCC1apC5E/9RTMGwYDB0Kn3wCF1zgvjjOPDM8Me7a5ao1xo6FmTMzPrZkSfdFXq5c6lazZurl0qVh927YutVVl2zdCkuXpl7OqLthoUKu33qzZm7m0lat4KyzIK/0qlu50n0JbdqUeSI9cCD9x3njjdyLOZ/54gv3MatdG2rVgho1vHwQH+9KZ999B506+R1m+iUIEblPVZ8XkeEE7256e7iDy4yVILJhy5ZjE8Jff7n9JUu6hNCxo9tiY1MTQnp27IDhw+Gll9wXbLduMGgQtG6d/TiPHHFr944dC5Mmwb59bsH3yy+HunWPTQApW9mymcecmX373HNJSRiBiWTbNvcL77ff4I8/Uttj6tY9NmFER7uqOL8lJ0NCAnz2mWsETUn+4Ko00r52wV7TtFvFii7hFpSSVA5Rhcceg//979j9hQq5JFGr5hFqzf2I2tHlqHVzd2rVckmkZk0oXjzn4gi1BJFRgrhAVb8QkWuC3a6q72QzxmyzBHGCZs92v04OHHAJoW3bYxPCiX6p7doFr70Ggwe7Eknnzq5E0b591h9rwQKXFMaNg/XrXRfAvn3h6qvdF3CkfDHt3Qvz5rmprufOhZ9+gg1e57uTTnIlrpSk0aqV+xbIjdj373elrJSksGGDG+ncrp2bVO+CC6BOHRv9nItU4dFH4YknoF8/eOABWLMmdVu92rs8L4nEvRVJ5tj35tRTU0sctWq5mU3OPffEYgk1QaCq6W64+ZNeyOgYP7cWLVqoyaLkZNU2bVSrVVP98UfVAwdy/hy7d6sOHqx6yimqoNqhg+r06e7cGdm0SXXoUNXmzd39ihRRveAC1YkTVffty/k4wyE5WfWff1QnTFC9+27Vtm1Vixd3zwfc637xxarPPac6aZJqQoLqv/9m/tqEYssW1bFjVXv3Vi1d2p2vVCl3fexY1c2bs38Oc0KSk1Uffti9Jdddp3rkSAYHjx+vBymiqz6cq7Nmqb7zjurjj7v7deqkWq+eatGiqoMGnXg8QIKG8B2b+QEwI5QH8mOzBHECvvzSve2vvx7+c+3Z477wq1Vz52zbVnXq1GO/DPftU/3oI9UePVQLF3bHtWih+vLLLmHkBwcOqP76q+rw4apXXKFat25qwkjZSpRQbdBA9bzzVG+4QfV//1MdM0Z15kzVFSvST+QrVqi+9JJLwimvX9WqqgMGqE6enHcSaz4WmByuvz6T5KCqumuX+1Fx223pHnLkSPbe2lATRCi9mF7EzbA6ATdILqXkMenECjc5x6qYsig5GZo3d1VBixblXv34/v1uSoZnnnGTu7VsCQMHwpw5bh3jHTugWjW32MxVV7lutPndtm2pdQr//OO2wMsbNx57vAhUrQqnnea2ypXh++9T2xOiotxAq169XLVWIVsLLBKoulrWp56CG25w7fohvTUXXQS//AJr14blvcx2G0TAA70dZLeqqu+zc1mCyKKPPoJLL4V333W9knLbgQPwzjvw9NPuy7BkSTcK9+qrXWWq1Yen2r/fJdO0iSPl8oYNrr2oZ0+XFGwupIijCg8/7D7uN94II0Zk4bt+3Dj3PzpnTs509kgjJxNEZVXdnGOR5SBLEFlw+LD7ZV60qOt54+eX8aFD8PPPrpdPmTL+xWFMmKjCQw+5QnP//vD661ksCOzY4Vbnu/VWePHFHI8v1ASRbsgicoGIJOGmw0gUkYwm2jORbuxY18//iSf8/6VetKjrSmvJweRDqvB//+eSw4ABJ5AcwHUlPu88N+4nkx/x4ZRR2E8B7VS1GtAbN923yYsOHIDHH3dVEhde6Hc0xuRbqvDgg/Dss3DTTa7X9wk3IcTHuyrFefNyNMasyCj0w6q6GI5OvGc/9/KqkSNdvfXTT0fO+AFj8hlVN7bhuefg5pvh1Vez2b7cs6cbXu3j3EwZTbVxsojcld51VX0pfGGZHLNnDzz5pBsE17mz39EYky+pwv33wwsvpCaHbP8Wq1jRdd6YONHVV/nw4y6j/PYmrtSQsqW9bvKCYcPcTKxPPWWlB2PCQBXuu88lh4EDcyg5pIiPhxUrfJs1Od0ShKo+npuBmDDYvh2efx7i4qCN9TEwJqepwr33uo5Gt9zipiTL0d9hF17oGjMmTnS9/nKZjabJzwYPdkniySf9jsSYfEcV7rnHJYdbbw1DcgA3Q3CHDr61Q1iCyK/+/ddNw33ppRAT43c0xuQrqnD33W4C49tuczW5YavBjY+HxYth4cIwnSB9mSYIETkpyL6K4QnH5JhnnnFTVj9uNYXG5KSUksOQIXD77fDyy2Fu3rvoIncCH0oRoZQgJonI0cn1RaQq8E0oDy4id4rI3yKyQEQ+EJHiIlJHRH4WkWUiMl5EinnHnuRdX+7dXvtEnpDBdWl97TW49lpo0MDvaIzJV0aPdiWHW291hfSw9/2oWtVNyR+hCeJTYIKIFPa+tKcCD2Z2JxGpDtwOxKpqFG7q8L7Ac8AQVa0PbANSFrW9HtimqvWAId5x5kQ88YT7O2iQv3EYk8/Mn+8aozt3zqXkkCI+3i3qtXRpLp3QyTRBqOqbuBLDp8AXwE2qOi3Exy8ClBCRIkBJYANubeuUVPgOkDK0t5d3He/2TiLWLzPLli2Dt992PR9q1fI7GmPyje3b3fd05cpuVdBcnbHm4ovd348/zsWTZjwX010pG1AcqAnMB1qlGUAXlKquAwYD/+ASww5gHrBdVQ97hyUC1b3L1YG13n0Pe8dXChJXfxFJEJGEpKSk0J5lQfLoo24ls//7P78jMSbfUHWrwK1Z4yZFzvXlx2vWdCsS5nI1U0YliMBBcaWBT4DlhDhQTkQq4EoFdYBqQCng/CCHpsxEFay0EGwt7JGqGquqsVXyyiLxueWPP+CDD+COO+CUU/yOxph848UX4dNP3WA434YU9e7t1kFftSrXThnOgXKdgVWqmgQgIpOANkB5ESnilRJqAOu94xNxpZREr0qqHLA1mzEULI884maBvPdevyMxJt/44Qc3x1Lv3u63l29693b/2x9/7LpR5YJQurl+IyLlA65XEJGpITz2P7jqqJJeW0InYCEwE4j3jrkG+My7/Ll3He/2GZrZYhUm1dy58MUXbsx/hQp+R2NMvrBpkxtK9J//uN5LvraK1qnjVgvMxWqmUHoxVVHV7SlXVHUbcHJmd/JmgJ0I/Ab85Z1rJHA/cJeILMe1MYzy7jIKqOTtvwt4IAvPwzz0kFtg5Pbb/Y7EmHzhyBG47DLXOD1xIpQt63dEuFLEzz+7pUhzQSgJ4oiInJZyRURqEaRtIBhVfVRVG6pqlKpepaoHVHWlqrZU1Xqq2kdVD3jH7veu1/NuX3liT6kAmj4dZsxwDdOlS/sdjTH5wqBBMHOmW/CnWTO/o/H07u3+TpqUK6cLZcnRbrhf/t95u9oD/VU1lGqmsLIlR3HdK1q1cmsUL10KxYv7HZExed5XX0GPHnDDDfDmm35Hk0Z0tCvO/PDDCT9EtpccTaGqU4DmwHhvaxEJycF4vvgCfvnF/dyx5GBMtq1eDVdd5aYwGzbM72iC6N0bZs92PwrDLNTJ+toAHb2tVbiCMVmUnOzaHurXh2uuyfx4Y0yGDhyAPn3cv9bEiVCihN8RBREf72oOPvkk7KfKaEU5AETkWeBMYJy36w4RaauqmU63YcLsww9hwQI39qFo0cyPN8Zk6K67ICHBfffWret3NOlo3NjVf+VC9gqlDeJPIEZVk73rhYHfVdX3ZpsC3QZx6JD7oJQsCb//ns3Fb40x778PV1zhhho8/7zf0YRXqG0QmZYgPOVJHbRW7oSjMjlnzBhYvhw+/9ySgzHZtHAh3HgjtGvnVuc1TigJ4hngdxGZiZsOoz1gE/34af9++N//XO+lHj38jsaYPG33btfuW7q0q7W12tpUmSYIVf1ARGbh2iEEuF9VN4Y7MJOB556DxEQYO9bnoZ3G5G2qruSwdCl8+y1Uq+Z3RJEllEbq6araCTcVRtp9JrctWgRPP+2GeJ5zjt/RGJOnvf66KzU8/bT9OwWTboIQkeK4NRwqezOzpvxULYubndXktuRkGDAASpVy6x0aY07YL7/Af/8LcXFw//1+RxOZMipBDAD+i0sG80hNEDuBV8Mclwnmrbfc6MnRo206b2OyYcsWN96hWjVXU2v9PILLaLrvl4GXReQ2VR2eizGZYDZscDO1duzo1po2xpyQw4fdSOmNG92A5IoV/Y4ocmW0otyZInJqSnIQkatF5DMRGSYi9pLmtjvucL2X3njDGqaNOUHJyXD99fD1124ajdhMRwIUbBkVrN4ADgKISHvgWWAsbinQkeEPzRz1xRcwYYJbEOj00/2Oxpg8SRVuu81VKT3+uGvOMxnLqA2isKqmDI67FBipqh8DH4vI/PCHZgDYtQsGDoSoKFspzpgTpAoPPgivveb+jR55xO+I8oaMShCFvaU/wa0GNyPgtlBHYJvsevhhWLcORo6EYsX8jsaYPOnpp93woZtvdn+tljY0GX3RfwB8JyKbgX3ADwAiUg9XzWTC7ZdfYPhwV4Jo3drvaIzJk4YOdb+zrroKXnnFkkNWZNSL6SkRmQ5UBaYFrA9dCLgtN4Ir0A4dcquVVKvmfv4YY7Js1Ci48064+GLXO9y6s2ZNhlVFqjo3yL6l4QvHHPXii/DXX/DppxGyGK4xecuHH7ppNLp1czO1FrGK8SwLWz4VkQYiMj9g2yki/xWRaBH5SUT+EpEvRKRswH0eFJHlIrJERLqGK7aIt3y562Zx8cXQq5ff0RiT53zxhatSatcOPv4YTjrJ74jyprAlCFVdoqoxqhoDtAD2Ap8AbwEPqGpT7/q9ACLSGOgLNAG6Aa95a08ULKpw002uQXq4jU80JqumT3ejpM84wyWKkiX9jijvyq0auU7AClVdAzQAvvf2fwP09i73Aj5U1QOqugpYDrTMpfgix9ix7hP+3HM2taQxWTRnDvTs6Vbh/fprq53NrtxKEH1xvaIAFgA9vct9gJre5erA2oD7JHr7jiEi/UUkQUQSkpKSwhSuT5KS3JqHbdpA//5+R2NMnvLbb9C9O1SvDt98A5Uq+R1R3hf2BCEixXAJYYK36zrgFhGZB5TBG61N6mSAgY5bD1VVR6pqrKrGVqlSJRwh++euu9zAuJEjrbuFMVmwcCF07Qrlyrl1HU491e+I8ofcaNc/H/hNVTcBqOpioAuAiJwOxHnHJZJamgCoAazPhfgiw9Sp8N57bohnkyZ+R2NMnrFyJZx3HhQu7JLDaaf5HVH+kRs/Uy8jtXoJETnZ+1sIeBgY4d30OdBXRE4SkTpAfeCXXIgv6w4edGtBb9+eM4+3Z49rmG7QAP7PVnM1JlSJidCpk5vH8ttvXduDyTlhTRAiUhI4D5gUsPsyEVkKLMaVEN4GUNW/gY+AhcAU4BZVPRLO+E7YY4+57qfVqsE117g1GvS42rDQPf44rF7tZmotXjynojQmX/v3X+jc2a3tMHWqm67M5CzR7Hyx+Sw2NlYTEhJy96SLFkF0tGsNq1oVxo1z7QYNGriRz1dfDSefHPrj/f47nHkm9OsHb74ZvriNyUe2bXNLhC5d6pJDu3Z+R5S3iMg8Vc10snNrCc0KVbjlFrfk58iRbkHbDRvg7behcmU3TWSNGq4T9tSpcCSTAtDhw26oZ+XK8PzzufMcjMnjFi92DdKLFrmJBiw5hI8liKz44AOYOROeeSa1lFCqlFvh7ccfXVeK226DWbPc+P7//MdVH61dG/zxhg+HefPcyiUVKuTWszAmT9qxA+65B5o2hSVL4KOPoEsXv6PK36yKKVQ7drhqpNNOg59+cl0m0nPggGvEfvNN1yFbxCWMG2+EHj2gaFHX5tCkiSsnf/GFTTFpTDqSk+Gdd+CBB9xQoeuvh6eeylpNrjlWqFVMNn1VqB55xLWKffVVxskB3MQvffq4bdUqVwU1erSbW+nkk12J47ffXFJ47TVLDrns4EH44w/XdHTo0IltycnuraxRI3WrVs2W7Mhpc+fC7bfDr7+6Ge8nT4YWLfyOquCwEkQofvvNNSTffLObUP5EHDkCU6bAW2+5EsORI26i+jvuyNlYTVDLl7tmoWnTYMYM2L37xB5HxBUARVxBMa1TTjk2aaTdqleHEiWy91wKgg0bXIlh7FjXF+T55+GKK+y3VE4JtQRhCSIzycnup8vq1a7is3z57D/mxo3w88+uuimz0og5Ibt2uUQwdarbVq50++vUcQ2cnTu7vgFFi2ZtC3y7du50/fAz2rZtOz62ypVdsjj9dGjcOHWrX99KIAcOwMsvwxNPuJLeXXe5oUFlyvgdWf5iVUw55a233Mpu776bM8kB3DwANo13jkpOdj2GUxLCnDmuk1ipUnDuue6LpksXqFcv536Fli2b+uWenj173IqxaRPHmjWuf8KECalDaAoXdkmicWNo1Cj1sRs0KBiljsmT4b//hWXL3G+nl16ygW9+sxJERpKS3H9ns2au95KVbyPKhg2uD8DUqe5vytyNZ5zhSgldu7p5DyP5V/m+fa5gunBh6rZokfuSTOklLeI6xKVNHA0b5o9f1kuXulXfJk92paqhQ+H88/2OKn+zEkROuP9+V1dhDckRZfp0uO8+1zQErrE4JSGcd55rB8grSpSAmBi3BTp40CWJwMSxcKFLhgcPph5XrZpLFA0auL8pW40akT/f465d8OSTMGSIm0Bg8GDXSzySE3pBYwkiPT/+6Hof3X9/xnUIJtfs2OHGIr75pqsqeuYZlxSioyP/yzCrihVzvaDTztt4+LBrT/n7b1fyWLzY/X3/fff6pChRIjVpBCaP00/3ZwGdgwddCW/zZvd38WLXVXXjRjeJwNNP2wyskciqmII5dAiaN3f/cYsWuYps46uvvoIBA1y10t13u/GHBaFePlSqrhd2StJI2ZYscT2tA//NTzvNJYqKFV2yCNxKlTp+X7CteHHXSJ+UdOwXf7Drmze7Y9M66yw3RrRlwVsWzHdWxZQdw4fDggXwySeWHHy2ZYurn373Xfdr+pNPXI9jcywRV7V2yinQvv2xt+3f76qrApPHsmWusXzPHti712379mU/jmLFoEoVt1Wu7NpOUi4H7j/lFJek8lvJL7+xBJFWYiI8+ijExVlPI599/DEMHAhbt8KgQa67oy0+n3XFi7vpKZo2zfi45GSXTFISxt69xyaQwG3fPteLK+2Xf+nS1lyXn1iCSOuuu1xF77Bh9kn3yaZNbk7Ejz92NX3Tprl2BhNehQqlViEZAzZZ37GmTnUd0x96yJWNTa5SdYvqNW4MX37pGqF//tmSgzF+sRJEiv374dZb3cice+/1O5oCJzHRLar31Vdu4Pro0a7XjTHGP5YgUjz/vJuwZ9o0q+jORapusPo997iavaFDXZ62GUiM8Z8lCIAVK1xH7EsvdSOtTK5YtcrNgD59upv1/K23rGbPmEgStjYIEWkgIvMDtp0i8l8RiRGRud6+BBFp6R0vIjJMRJaLyJ8i0jxcsR1D1f1kLVbMTf5iwk7V9SSOinLTXL3xhltw3pKDMZElbCUIVV0CxACISGFgHfAJ8CbwuKp+LSLdgeeBjsD5QH1vOwt43fsbXp984qbhHjLEzVtgwkrVTafw6qtuvp033oCaNf2OyhgTTG71YuoErFDVNYACZb395YD13uVewFh15gLlRaRqWKPavdutx9CsmStFmLAKTA733OMapC05GBO5cqsNoi/wgXf5v8BUERmMS1BtvP3VgcDFmxO9fRsCH0hE+gP9AU477bTsRfW//7nuM+PHQxFrjgknVbcy2Kuvuqkynn/ehpkYE+nCXoIQkWJAT2CCt+tm4E5VrQncCYxKOTTI3Y+bKEpVR6pqrKrGVqlS5cQDW7DAVStdf72bE9qEjaorqL3yihuH+MILlhyMyQtyo4rpfOA3Vd3kXb8GmORdngCkTNWVCARWONQgtfopZ6m6ORzKloVnnw3LKYyj6haBGT7czak0eLAlB2PyitxIEJeRWr0E7ku/g3f5XGCZd/lz4GqvN1MrYIeqHlO9lGPGjYMffoDnnnMTyZiwUHVJYdgwlyRefNGSgzF5SVgr3kWkJHAeMCBg943AyyJSBNiP154ATAa6A8uBvUC/sAUWF+eSw3XXhe0UBV1Kcnj5ZZccXnrJkoMxeY2tB2FynKpraxg61LU9DBliycGYSBLqehA2WZ/JUaqul5IlB2PyPksQJseouvENQ4a4Lq2WHIzJ2yxBmByh6ibBfeklNxhu6FBLDsbkdZYgTLalJIcXX3QD0l9+2ZKDMfmBJQiTLapw332pycEW4jMm/7AEYU6YKtx/vxv8dsstlhyMyW8sQZgTogoPPOCmzRg40I2UtuRgTP5iCcJkmSo8+KCbcO/mm90cS5YcjMl/bApTkyVHjrjxDa++asnBmPzOEoQJ2YEDcNVVMGGCG+/w3HNQyMqgxuRbliBMSHbuhIsughkzXKP03Xf7HZExJtwsQZhMbdwI3bvDX3/Bu+/ClVf6HZExJjdYgjAZWrECunRxSeLzz9060saYgsEShEnX779Dt26uYXrGDDjrLL8jMsbkJmtiNEHNmAEdOkDx4vDjj5YcjCmILEGY43z0katKqlUL5syBhg39jsgY4wdLEOYYr7wCfftCy5bw/fdQvbrfERlj/GIJwgBudPQjj7ipui+4AKZNgwoV/I7KGOMna6Q2HD7sRkW/9RZcfz2MGAFF7JNhTIEXthKEiDQQkfkB204R+a+IjA/Yt1pE5gfc50ERWS4iS0Ska7hiM6n27YP4eJccHnoI3nzTkoMxxgnbV4GqLgFiAESkMLAO+ERVh6YcIyIvAju8y42BvkAToBrwrYicrqpHwhVjQbdtG/TsCbNnu6m6b7vN74iMMZEkt34rdgJWqOqalB0iIsAlwLnerl7Ah6p6AFglIsuBlsBPuRRjgbJunRvjsGQJfPABXHqp3xEZYyJNbjVS9wU+SLOvHbBJVZd516sDawNuT/T2HUNE+otIgogkJCUlhSXY/Cw5GSZNgjZtYPVqmDzZkoMxJriwJwgRKQb0BCakuekyjk0awSaN1uN2qI5U1VhVja1SpcoJxaTqtoLk0CEYOxaioqB3byhWDGbNgs6d/Y7MGBOpcqMEcT7wm6puStkhIkWAi4HxAcclAjUDrtcA1ocjoF9+gSZNYOhQ2Lo1HGeIHPv2ubUb6teHa66BokVdldKiRdCihd/RGWMiWW4kiLQlBYDOwGJVTQzY9znQV0ROEpE6QH3gl3AEdO6WMjAAAAjXSURBVPAglC0Ld97pBoJdfbVrqM1PpYqdO916DbVrw623uuf55Zcwf74bCGc9lYwxmQlrghCRksB5wKQ0Nx3XJqGqfwMfAQuBKcAt4erB1K4dzJ3rJqO79lr49FM4+2xo1syNJN6+PRxnzR1JSfDww3DaaW7N6DPOgO++c/MpxcXZ6m/GmNCJ5uGfzbGxsZqQkJDtx9m921W7vPEGzJsHJUq4X9kDBrgpJ/LCl+ratfDiizByJOzfDxdf7NaNtmokY0xaIjJPVWMzO86m2gBKl4Ybb4SEBLddeaWbsK5VK/cL/PXXXZVNJFq61I1+rlvXtTVceiksXAgTJ1pyMMZkjyWINFq0cL/C1693iUEEBg6EatVSk4jfVOG331wyaNgQ3n/flXaWL4e337bZV40xOcOqmDKhCr/+6qqfPvjA9Qpq3hz69XNfxKeeClWrQsWKOVsVlZwMiYnuSz/Ytm+fa2i/5Ra44w445ZScO7cxJn8LtYrJEkQW7NgB773nksVffx17W9Gi7ku6atXUpHHqqcderlrVHVO8uLvP4cPwzz/BE8DKlXDgQOrjFyvmqpHq1XNbw4ZwySVQvnyuPX1jTD5hCSKMVN1azevXw4YNbr3mlL+Bl5OSgnedLV8eypVz010cPpy6v0SJ1ASQdqteHQoXzr3naIzJv0JNENYb/gSIpH5xZ+TQIZckApNGyt9t21xX1JTHqV/flTDyQo8pY0zBYAkijIoWdY3b1ar5HYkxxmSd9WIyxhgTlCUIY4wxQVmCMMYYE5QlCGOMMUFZgjDGGBOUJQhjjDFBWYIwxhgTlCUIY4wxQeXpqTZEJAlYc4J3rwxszsFwclqkxweRH6PFlz0WX/ZEcny1VLVKZgfl6QSRHSKSEMpcJH6J9Pgg8mO0+LLH4sueSI8vFFbFZIwxJihLEMYYY4IqyAlipN8BZCLS44PIj9Hiyx6LL3siPb5MFdg2CGOMMRkryCUIY4wxGbAEYYwxJqh8nyBEpJuILBGR5SLyQJDbTxKR8d7tP4tI7VyMraaIzBSRRSLyt4jcEeSYjiKyQ0Tme9ug3IrPO/9qEfnLO/dx67uKM8x7/f4Ukea5GFuDgNdlvojsFJH/pjkm118/ERktIv+KyIKAfRVF5BsRWeb9rZDOfa/xjlkmItfkYnwviMhi7z38RESCrnae2echjPE9JiLrAt7H7uncN8P/9zDGNz4gttUiMj+d+4b99ctRqppvN6AwsAL4D1AM+ANonOaYgcAI73JfYHwuxlcVaO5dLgMsDRJfR+BLH1/D1UDlDG7vDnwNCNAK+NnH93ojbgCQr68f0B5oDiwI2Pc88IB3+QHguSD3qwis9P5W8C5XyKX4ugBFvMvPBYsvlM9DGON7DLgnhM9Ahv/v4Yovze0vAoP8ev1ycsvvJYiWwHJVXamqB4EPgV5pjukFvONdngh0EsmdlaFVdYOq/uZd3gUsAqrnxrlzUC9grDpzgfIiUtWHODoBK1T1REfW5xhV/R7YmmZ34OfsHeDCIHftCnyjqltVdRvwDdAtN+JT1Wmqeti7OheokdPnDVU6r18oQvl/z7aM4vO+Oy4BPsjp8/ohvyeI6sDagOuJHP8FfPQY7x9kB1ApV6IL4FVtnQH8HOTm1iLyh4h8LSJNcjUwUGCaiMwTkf5Bbg/lNc4NfUn/n9LP1y/FKaq6AdwPA+DkIMdEymt5Ha5UGExmn4dwutWrAhudThVdJLx+7YBNqrosndv9fP2yLL8niGAlgbT9ekM5JqxE5P/bu5cQOaoojOP/TyYiagxKhCi6MEEXgiTIGDQRUQjBiAR8LJSgom4CanTnIhtx5UIUEXFhBEGyUImPWQQMKLiTDARNfBHHXUiYiAvDEBHNHBf3FhblrTjTdlW1w/eDorur7tBnTt/q03XrUnUpcAB4LiLONDYfIQ2bbAReBz7uMzZga0TcDOwAnpJ0R2P7JOTvQmAn8EFh89D5W45JyOVe4E9gf0uTf+sPXXkT2ABsAk6RhnGaBs8f8DDnP3oYKn8jWekF4gRwbe31NcDJtjaSpoA1jHZ4OxJJq0jFYX9EfNjcHhFnImIhPz8IrJK0tq/4IuJkfjwNfEQ6jK9bSo67tgM4EhHzzQ1D569mvhp6y4+nC20GzWU+KX4vsCvygHnTEvpDJyJiPiLORcQi8FbL+w6dvyngfuC9tjZD5W9UK71AzALXS7ou/8p8CJhptJkBqtkiDwKft+0c45bHK98Gvo+IV1rarKvOiUjaTPrMfukpvkskra6ek05kftNoNgM8mmcz3Qr8Wg2l9Kj1V9uQ+Wuo97PHgE8KbT4Ftku6PA+hbM/rOifpbuB5YGdEnG1ps5T+0FV89fNa97W871L29y5tA36IiBOljUPmb2RDnyXveiHNsjlOmt2wN697kbQjAFxEGpqYAw4D63uM7XbSIfBR4Ku83APsBnbnNk8D35JmZHwJbOkxvvX5fb/OMVT5q8cn4I2c32PAdM+f78WkL/w1tXWD5o9UrE4Bf5B+1T5JOq/1GfBjfrwit50G9tX+9oncF+eAx3uMb440fl/1w2pm39XAwfP1h57iezf3r6OkL/2rmvHl1//Y3/uIL69/p+p3tba952+ciy+1YWZmRSt9iMnMzEbkAmFmZkUuEGZmVuQCYWZmRS4QZmZWNDV0AGb/B5KqaaoA64BzwM/59dmI2DJIYGYd8jRXs2WS9AKwEBEvDx2LWZc8xGT2H0layI93SvpC0vuSjkt6SdIuSYfzPQA25HZXSjogaTYvW4f9D8zKXCDMxmsj8CxwE/AIcENEbAb2Ac/kNq8Br0bELcADeZvZxPE5CLPxmo18LSpJPwGH8vpjwF35+TbgxtptRy6TtDrSPUHMJoYLhNl4/V57vlh7vcjf+9sFwG0R8VufgZktl4eYzPp3iHQRQQAkbRowFrNWLhBm/dsDTOe7o31Huvqs2cTxNFczMyvyEYSZmRW5QJiZWZELhJmZFblAmJlZkQuEmZkVuUCYmVmRC4SZmRX9BcM41srtPoStAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the real stock prices\n",
    "plt.plot(real_stock_price, color = \"red\", label = \"Real Google Stock Price\")\n",
    "\n",
    "# plotting the predicted stock prices\n",
    "plt.plot(predicted_stock_prices, color = \"blue\", label = \"Predicted Stock Price\")\n",
    "\n",
    "plt.title(\"Google Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.legend() # sol üstteki renklerin temsil ettiği bilgiler\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü gibi yükselen ve düşen trendler yeteri kadar iyi bir şekilde tespit edilebiliyor, sadece bazı dik iniş çıkışlar tam olarak tahmin edilememiş ancak sonuçları yine yakın ve iyi değerlerde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Regression, the way to evaluate the model performance is with a metric called RMSE (Root Mean Squared Error). It is calculated as the root of the mean of the squared differences between the predictions and the real values.<br>\n",
    "\n",
    "However for our specific Stock Price Prediction problem, evaluating the model with the RMSE does not make much sense, since we are more interested in the directions taken by our predictions, rather than the closeness of their values to the real stock price. We want to check if our predictions follow the same directions as the real stock price and we don’t really care whether our predictions are close the real stock price. The predictions could indeed be close but often taking the opposite direction from the real stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.052722576142806\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_prices))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then consider dividing this RMSE by the range of the Google Stock Price values of January 2017 (that is around 800) to get a relative error, as opposed to an absolute error. It is more relevant since for example if you get an RMSE of 50, then this error would be very big if the stock price values ranged around 100, but it would be very small if the stock price values ranged around 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>here are different ways to improve the RNN model:</b><br>\n",
    "\n",
    "-Getting more training data: we trained our model on the past 5 years of the Google Stock Price but it would be even better to train it on the past 10 years.<br>\n",
    "-Increasing the number of timesteps: the model remembered the stock prices from the 60 previous financial days to predict the stock price of the next day. That’s because we chose a number of 60 timesteps (3 months). You could try to increase the number of timesteps, by choosing for example 120 timesteps (6 months).<br>\n",
    "-Adding some other indicators: if you have the financial instinct that the stock price of some other companies might be correlated to the one of Google, you could add this other stock price as a new indicator in the training data.<br>\n",
    "-Adding more LSTM layers: we built a RNN with four LSTM layers but you could try with even more.<br>\n",
    "-Adding more neurones in the LSTM layers: we highlighted the fact that we needed a high number of neurones in the LSTM layers to respond better to the complexity of the problem and we chose to include 50 neurones in each of our 4 LSTM layers. You could try an architecture with even more neurones in each of the 4 (or more) LSTM layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tunning the RNN</b><br>\n",
    "Remember, this time we are dealing with a Regression problem because we predict a continuous outcome (the Google Stock Price).<br>\n",
    "Parameter Tuning for Regression is the same as Parameter Tuning for Classification which you learned in Part 1 - Artificial Neural Networks, the only difference is that you have to replace:<br>\n",
    "\n",
    "scoring = 'accuracy'  <br>\n",
    "\n",
    "by:<br>\n",
    "\n",
    "scoring = 'neg_mean_squared_error' <br>\n",
    "\n",
    "in the GridSearchCV class parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
